{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"ReCoDE - Neutron Diffusion Model Description This code is part of the Re search Co mputing and D ata Science E xamples (ReCoDE) project. The code itself is a 1-dimensional neutron diffusion solver written in Fortran in an object-oriented format. The example will focus on features of the code that can be used as a teaching aid to give readers some experience with the concepts such that they can implement them in the exercises or directly in their own codes. An understanding of neutron diffusion and reactor physics is not required for this example, but a discussion of the theory can be found in the bottom section of this readme. Learning Outcomes Compiled Codes and Makefiles Compiler Directives Object-Oriented Programming Reading input data from file Generating output files Using ParaView to visualise numerical results Solving mathematical problems Discretisation of a spatial dimension Optimised data storage Using build tools CMake and fpm Incorporating external libraries (PETSc) Requirements Academic Entry level researcher with basic knowledge of Fortran syntax. For a Fortran crash course see here System Program Version Anaconda >=4.13.0 Getting Started You will be needing Anaconda and a shell/bash terminal to run this code. Optionally, you can use Visual Studio Code as your code editor to work on the exemplar. Creating the Anaconda Environment The first thing required to build the project is to create the Anaconda environment that contains all the necessary tools to run the exemplar. This can be done by running the following command in a terminal: conda env create -f environment.yml You have now created a new Anaconda environment. To activate your Anaconda environment run: conda activate diffusion All the following steps take place from a terminal that has the diffusion Anaconda environment activated. Compiling the Code As Fortran is a compiled language, the code must first be compiled before it can be executed. To do so, a convenience script has been included to get you started: ./install.sh or alternatively fpm build This runs a few commands, feel free to peek into the install.sh file to see how the code is compiled, although we will be covering building/compiling in detail in sections 3 - Compilation Basics and 7 - Build Tools . The summary of the script is that it calls cmake which configures your project by checking for dependencies and generating the necessary Makefiles for compilation. It then compiles the project using the generated Makefiles , and then it finally installs the program inside a folder called install/bin . To run the installed program, run the following command in a terminal: ./install/bin/diffusion or alternatively fpm run This command tells the executable to run and will generate relevant output files containing the solution to the problem. Input Options The code is designed such that the user can easily change the problem which the code is attempting to solve. The code uses the input file input.in to read details about the problem, such as the positions of boundaries or materials in the problem. An example of such an input can be seen below: ------------------------------------------ Regions: - Integer number of regions in the problem 2 ------------------------------------------ Boundaries: - Real number positions of the boundaries between the regions (one per line) 0.0 0.5 1.0 ------------------------------------------ Nodes: - Integer number of nodes in each region (one per line) 5 5 ------------------------------------------ Materials: - Fuel, Water or Steel (one per line) Fuel Fuel ------------------------------------------ Boundary_Conditions: - Zero or Reflective (two parameters - one per line) Zero Zero ------------------------------------------ For this example problem, we are stating that we have a geometry ranging from x = 0.0 to 1.0 , half fuel and half steel with a central boundary at x = 0.5 . As seen from the above input, the code needs four different parameters to be described to it. Anatomy of input.in Regions - An integer number of regions that exists within the problem. We have 1 region from 0.0 to 0.5 and another from 0.5 to 1.0 , hence we give the code the integer number 2 . Boundaries - The positions of the boundaries within the problem. Our first boundary is at the start of our geometry, so we enter the number 0.0 . We then have an internal boundary halfway through the problem separating the regions, so we enter the number 0.5 . Finally, we have the exterior boundary of our geometry, so we enter the number 1.0 . The code will always read one more value here than the number of regions in the problem. Nodes - This describes how refined we want the geometry in each region. For the example we want a quick solve with just enough nodes to see the flux profile. As we need to describe this for each region we enter the value 10 twice. The code will always read the same number of values here as the number of regions in the problem. Materials - This described the materials that are present within the system. The first half of our geometry is fuel, with the latter half being Steel, so we enter Fuel and Steel . The code will always read the same number of values here as the number of regions in the problem. Boundary Conditions - This tells the code what boundaries exist at the edges of our problem. Two boundary conditions have been implemented in out code, that of 'Zero' and 'Reflective'. The former simply ensures that the flux will tend to zero at the boundary, while the latter ensures that the derivative of the flux will tend to zero at the boundary. Reading Output Files The code generates two output files, OutputFile.txt and OutputFile.vtu . The former is a simple text file containing the position and flux of the solution to the problem. These are simply given in two columns such that they can be read easily by something like a GNUPlot or Python script. An example of such a flux profile can be seen below: 0.000000E+00 0.135813E+01 0.166667E+00 0.137306E+01 0.333333E+00 0.141907E+01 0.500000E+00 0.150000E+01 0.666667E+00 0.158093E+01 0.833333E+00 0.162694E+01 0.100000E+01 0.164187E+01 The results can easily then be visualised using Python, Excel, GNUPlot or any other drawing tool. The OutputFile.vtu file stores additional data such as the region and cell numbers in an XML format. This can be directly read by software such as ParaView, allowing for more interactive visualisations than that of the previous flux profile. For visualisation purposes, the data has been smeared in a second dimension, which should give users an idea of how multidimensional cell data can be viewed. An example output from ParaView can be seen in the image below by running the following command in a terminal: paraview OutputFile.vtu Project Structure . \u251c\u2500\u2500 app \u2502 \u2514\u2500\u2500 main.F90 \u251c\u2500\u2500 docs \u251c\u2500\u2500 environment.yml \u251c\u2500\u2500 fpm.toml \u251c\u2500\u2500 input.in \u251c\u2500\u2500 install \u2502 \u251c\u2500\u2500 bin \u2502 \u2502 \u2514\u2500\u2500 diffusion \u2502 \u251c\u2500\u2500 include \u2502 \u2514\u2500\u2500 lib \u2502 \u251c\u2500\u2500 libdiffusion.a \u2502 \u2514\u2500\u2500 libdiffusion.so \u251c\u2500\u2500 install.sh \u251c\u2500\u2500 mkdocs.yml \u251c\u2500\u2500 README.md \u251c\u2500\u2500 solutions \u251c\u2500\u2500 src \u2502 \u251c\u2500\u2500 Constants.F90 \u2502 \u251c\u2500\u2500 CRS.F90 \u2502 \u251c\u2500\u2500 Materials.F90 \u2502 \u251c\u2500\u2500 MatGen.F90 \u2502 \u251c\u2500\u2500 Matrix_Base.F90 \u2502 \u251c\u2500\u2500 Output.F90 \u2502 \u251c\u2500\u2500 PETSc \u2502 \u2502 \u251c\u2500\u2500 PETSc_Init.F90 \u2502 \u2502 \u251c\u2500\u2500 PETSc_Ksp.F90 \u2502 \u2502 \u251c\u2500\u2500 PETSc_Mat.F90 \u2502 \u2502 \u2514\u2500\u2500 PETSc_Vec.F90 \u2502 \u251c\u2500\u2500 PETScSolver.F90 \u2502 \u251c\u2500\u2500 Problem.F90 \u2502 \u2514\u2500\u2500 Solver.F90 \u2514\u2500\u2500 tools \u251c\u2500\u2500 fluxplot \u2514\u2500\u2500 plot.py","title":"Home"},{"location":"#recode-neutron-diffusion-model","text":"","title":"ReCoDE - Neutron Diffusion Model"},{"location":"#description","text":"This code is part of the Re search Co mputing and D ata Science E xamples (ReCoDE) project. The code itself is a 1-dimensional neutron diffusion solver written in Fortran in an object-oriented format. The example will focus on features of the code that can be used as a teaching aid to give readers some experience with the concepts such that they can implement them in the exercises or directly in their own codes. An understanding of neutron diffusion and reactor physics is not required for this example, but a discussion of the theory can be found in the bottom section of this readme.","title":"Description"},{"location":"#learning-outcomes","text":"Compiled Codes and Makefiles Compiler Directives Object-Oriented Programming Reading input data from file Generating output files Using ParaView to visualise numerical results Solving mathematical problems Discretisation of a spatial dimension Optimised data storage Using build tools CMake and fpm Incorporating external libraries (PETSc)","title":"Learning Outcomes"},{"location":"#requirements","text":"","title":"Requirements"},{"location":"#academic","text":"Entry level researcher with basic knowledge of Fortran syntax. For a Fortran crash course see here","title":"Academic"},{"location":"#system","text":"Program Version Anaconda >=4.13.0","title":"System"},{"location":"#getting-started","text":"You will be needing Anaconda and a shell/bash terminal to run this code. Optionally, you can use Visual Studio Code as your code editor to work on the exemplar.","title":"Getting Started"},{"location":"#creating-the-anaconda-environment","text":"The first thing required to build the project is to create the Anaconda environment that contains all the necessary tools to run the exemplar. This can be done by running the following command in a terminal: conda env create -f environment.yml You have now created a new Anaconda environment. To activate your Anaconda environment run: conda activate diffusion All the following steps take place from a terminal that has the diffusion Anaconda environment activated.","title":"Creating the Anaconda Environment"},{"location":"#compiling-the-code","text":"As Fortran is a compiled language, the code must first be compiled before it can be executed. To do so, a convenience script has been included to get you started: ./install.sh or alternatively fpm build This runs a few commands, feel free to peek into the install.sh file to see how the code is compiled, although we will be covering building/compiling in detail in sections 3 - Compilation Basics and 7 - Build Tools . The summary of the script is that it calls cmake which configures your project by checking for dependencies and generating the necessary Makefiles for compilation. It then compiles the project using the generated Makefiles , and then it finally installs the program inside a folder called install/bin . To run the installed program, run the following command in a terminal: ./install/bin/diffusion or alternatively fpm run This command tells the executable to run and will generate relevant output files containing the solution to the problem.","title":"Compiling the Code"},{"location":"#input-options","text":"The code is designed such that the user can easily change the problem which the code is attempting to solve. The code uses the input file input.in to read details about the problem, such as the positions of boundaries or materials in the problem. An example of such an input can be seen below: ------------------------------------------ Regions: - Integer number of regions in the problem 2 ------------------------------------------ Boundaries: - Real number positions of the boundaries between the regions (one per line) 0.0 0.5 1.0 ------------------------------------------ Nodes: - Integer number of nodes in each region (one per line) 5 5 ------------------------------------------ Materials: - Fuel, Water or Steel (one per line) Fuel Fuel ------------------------------------------ Boundary_Conditions: - Zero or Reflective (two parameters - one per line) Zero Zero ------------------------------------------ For this example problem, we are stating that we have a geometry ranging from x = 0.0 to 1.0 , half fuel and half steel with a central boundary at x = 0.5 . As seen from the above input, the code needs four different parameters to be described to it.","title":"Input Options"},{"location":"#anatomy-of-inputin","text":"Regions - An integer number of regions that exists within the problem. We have 1 region from 0.0 to 0.5 and another from 0.5 to 1.0 , hence we give the code the integer number 2 . Boundaries - The positions of the boundaries within the problem. Our first boundary is at the start of our geometry, so we enter the number 0.0 . We then have an internal boundary halfway through the problem separating the regions, so we enter the number 0.5 . Finally, we have the exterior boundary of our geometry, so we enter the number 1.0 . The code will always read one more value here than the number of regions in the problem. Nodes - This describes how refined we want the geometry in each region. For the example we want a quick solve with just enough nodes to see the flux profile. As we need to describe this for each region we enter the value 10 twice. The code will always read the same number of values here as the number of regions in the problem. Materials - This described the materials that are present within the system. The first half of our geometry is fuel, with the latter half being Steel, so we enter Fuel and Steel . The code will always read the same number of values here as the number of regions in the problem. Boundary Conditions - This tells the code what boundaries exist at the edges of our problem. Two boundary conditions have been implemented in out code, that of 'Zero' and 'Reflective'. The former simply ensures that the flux will tend to zero at the boundary, while the latter ensures that the derivative of the flux will tend to zero at the boundary.","title":"Anatomy of input.in"},{"location":"#reading-output-files","text":"The code generates two output files, OutputFile.txt and OutputFile.vtu . The former is a simple text file containing the position and flux of the solution to the problem. These are simply given in two columns such that they can be read easily by something like a GNUPlot or Python script. An example of such a flux profile can be seen below: 0.000000E+00 0.135813E+01 0.166667E+00 0.137306E+01 0.333333E+00 0.141907E+01 0.500000E+00 0.150000E+01 0.666667E+00 0.158093E+01 0.833333E+00 0.162694E+01 0.100000E+01 0.164187E+01 The results can easily then be visualised using Python, Excel, GNUPlot or any other drawing tool. The OutputFile.vtu file stores additional data such as the region and cell numbers in an XML format. This can be directly read by software such as ParaView, allowing for more interactive visualisations than that of the previous flux profile. For visualisation purposes, the data has been smeared in a second dimension, which should give users an idea of how multidimensional cell data can be viewed. An example output from ParaView can be seen in the image below by running the following command in a terminal: paraview OutputFile.vtu","title":"Reading Output Files"},{"location":"#project-structure","text":". \u251c\u2500\u2500 app \u2502 \u2514\u2500\u2500 main.F90 \u251c\u2500\u2500 docs \u251c\u2500\u2500 environment.yml \u251c\u2500\u2500 fpm.toml \u251c\u2500\u2500 input.in \u251c\u2500\u2500 install \u2502 \u251c\u2500\u2500 bin \u2502 \u2502 \u2514\u2500\u2500 diffusion \u2502 \u251c\u2500\u2500 include \u2502 \u2514\u2500\u2500 lib \u2502 \u251c\u2500\u2500 libdiffusion.a \u2502 \u2514\u2500\u2500 libdiffusion.so \u251c\u2500\u2500 install.sh \u251c\u2500\u2500 mkdocs.yml \u251c\u2500\u2500 README.md \u251c\u2500\u2500 solutions \u251c\u2500\u2500 src \u2502 \u251c\u2500\u2500 Constants.F90 \u2502 \u251c\u2500\u2500 CRS.F90 \u2502 \u251c\u2500\u2500 Materials.F90 \u2502 \u251c\u2500\u2500 MatGen.F90 \u2502 \u251c\u2500\u2500 Matrix_Base.F90 \u2502 \u251c\u2500\u2500 Output.F90 \u2502 \u251c\u2500\u2500 PETSc \u2502 \u2502 \u251c\u2500\u2500 PETSc_Init.F90 \u2502 \u2502 \u251c\u2500\u2500 PETSc_Ksp.F90 \u2502 \u2502 \u251c\u2500\u2500 PETSc_Mat.F90 \u2502 \u2502 \u2514\u2500\u2500 PETSc_Vec.F90 \u2502 \u251c\u2500\u2500 PETScSolver.F90 \u2502 \u251c\u2500\u2500 Problem.F90 \u2502 \u2514\u2500\u2500 Solver.F90 \u2514\u2500\u2500 tools \u251c\u2500\u2500 fluxplot \u2514\u2500\u2500 plot.py","title":"Project Structure"},{"location":"1-numerics/","text":"1 - Introduction Solving Mathematical Problems In order to generate a solution to our problem we must first convert the general equation that we wish to solve into a system of equations. Scientific problems will often consist of a series of known properties of a system which, when multiplied by an unknown parameter, generate known values. Such systems of equations can be converted into a matrix and vector problem of the form Ax=b , where A is our matrix describing the properties of the system, x is a vector containing our unknown parameter of interest and b is a known parameter of the system. Simple matrix mathematics tells us that this could be trivially solved if we can invert the matrix A , such that: A x = b A^{-1} A x = A^{-1} b x = A^{-1} b Where A^{-1} is the inverse of the matrix A . Our system produces a relatively simple Tri-diagonal matrix (where only the 3 main diagonals contain data), and as such can be inverted through a number of relatively simple algorithms (such as the Thomas Algorithm). While this would be an optimal way of solving such a problem, this is only for a specific case and not generally applicable to a wide range of problems. As such, we have instead incorporated an iterative solver which progressively approximates the solution to the problem. As the algorithm iterates, the error between the values of Ax and b are compared, where the problem is 'solved' once this error passes below a certain threshold. Such solvers are widely used throughout scientific computing as they are widely applicable to a range of different problems involving a range of different matrices. While the commonly used Conjugate Gradient (CG) method is serviceable for a number of different problems, it does require the matrix A to be symmetric, a limitation which we would ideally like to avoid for this code. As such we have implemented the Bi-Conjugate Gradient (BCG) method for our solver, a modified form of the CG algorithm which can handle asymmetric matrices. Discretisation using Finite Difference Methods While our code could solve problems that involve homogenous systems, real systems will have properties that vary in some dimensions. A 1-Dimensional code such as this example code can facilitate variations in properties in the x dimension. To do so, we must have some method of discretising our spatial x dimension which allows us to consistently generate relevant systems of equations to describe the system. The specific discretisation scheme that we utilise in our code is known as 'finite difference', a scheme that generates very simple systems of equations, especially in a one-dimensional case. This discretisation scheme can be seen in the image below, where we split the domain into nodes from 0 to n . Each non-boundary node i will therefore have corresponding neighbouring nodes i-1 and i+1 which will need to be incorporated into a specific equation for the resulting solution to the node, described in further detail in the Theory section. This therefore generates a system of equations of the form: P*{i-1}\\phi*{i-1} + P*{i}\\phi*{i} + P*{i+1}\\phi*{i+1} = S\\_{i} Where P is some property of the system given by the scientific equation of interest, \\phi are the properties of interest that are being solved for (in our case neutron flux), and S is a known result of the system (in our case the source of neutrons). As can be seen from the above equation, the solution at one node i only depends on its immediate neighbours, so any matrix created for the system will be tridiagonal, meaning that only the main and adjacent diagonals will be filled.","title":"1 - Introduction"},{"location":"1-numerics/#1-introduction","text":"","title":"1 - Introduction"},{"location":"1-numerics/#solving-mathematical-problems","text":"In order to generate a solution to our problem we must first convert the general equation that we wish to solve into a system of equations. Scientific problems will often consist of a series of known properties of a system which, when multiplied by an unknown parameter, generate known values. Such systems of equations can be converted into a matrix and vector problem of the form Ax=b , where A is our matrix describing the properties of the system, x is a vector containing our unknown parameter of interest and b is a known parameter of the system. Simple matrix mathematics tells us that this could be trivially solved if we can invert the matrix A , such that: A x = b A^{-1} A x = A^{-1} b x = A^{-1} b Where A^{-1} is the inverse of the matrix A . Our system produces a relatively simple Tri-diagonal matrix (where only the 3 main diagonals contain data), and as such can be inverted through a number of relatively simple algorithms (such as the Thomas Algorithm). While this would be an optimal way of solving such a problem, this is only for a specific case and not generally applicable to a wide range of problems. As such, we have instead incorporated an iterative solver which progressively approximates the solution to the problem. As the algorithm iterates, the error between the values of Ax and b are compared, where the problem is 'solved' once this error passes below a certain threshold. Such solvers are widely used throughout scientific computing as they are widely applicable to a range of different problems involving a range of different matrices. While the commonly used Conjugate Gradient (CG) method is serviceable for a number of different problems, it does require the matrix A to be symmetric, a limitation which we would ideally like to avoid for this code. As such we have implemented the Bi-Conjugate Gradient (BCG) method for our solver, a modified form of the CG algorithm which can handle asymmetric matrices.","title":"Solving Mathematical Problems"},{"location":"1-numerics/#discretisation-using-finite-difference-methods","text":"While our code could solve problems that involve homogenous systems, real systems will have properties that vary in some dimensions. A 1-Dimensional code such as this example code can facilitate variations in properties in the x dimension. To do so, we must have some method of discretising our spatial x dimension which allows us to consistently generate relevant systems of equations to describe the system. The specific discretisation scheme that we utilise in our code is known as 'finite difference', a scheme that generates very simple systems of equations, especially in a one-dimensional case. This discretisation scheme can be seen in the image below, where we split the domain into nodes from 0 to n . Each non-boundary node i will therefore have corresponding neighbouring nodes i-1 and i+1 which will need to be incorporated into a specific equation for the resulting solution to the node, described in further detail in the Theory section. This therefore generates a system of equations of the form: P*{i-1}\\phi*{i-1} + P*{i}\\phi*{i} + P*{i+1}\\phi*{i+1} = S\\_{i} Where P is some property of the system given by the scientific equation of interest, \\phi are the properties of interest that are being solved for (in our case neutron flux), and S is a known result of the system (in our case the source of neutrons). As can be seen from the above equation, the solution at one node i only depends on its immediate neighbours, so any matrix created for the system will be tridiagonal, meaning that only the main and adjacent diagonals will be filled.","title":"Discretisation using Finite Difference Methods"},{"location":"2-oop/","text":"2 - Object-Oriented Programming Introduction Object-Oriented Programming (OOP) is a method of coding by which a piece of software is designed around the different required data types and classes which will be used in the programme. In its simplest sense, this translates to a code which is made of multiple different modules which make use of one another, rather than one large block of code. This style of programming is particularly advantageous when working with large coding projects, such as those used in research or data science. OOP codes are also much easier to read once their structure has been understood. As such, this section of the readme will give an explanation of how the Diffusion Code project is structured. At its simplest level, the code reads a specified problem from an input file, converts that to a system of equations which can then be solved, and outputs the resulting data to a set of files which can be read by an external program such a GNUPlot or ParaView. \\text{Input File } \\rightarrow \\text{Generate Equations } \\rightarrow \\text{Solve } \\rightarrow \\text{Output File } This explanation can now be further expanded in terms of complexity, where the structure will be given in terms files and modules. For the sake of readability, this is given as a full flow chart below. The Problem module reads through the input file, storing relevant data or passing it to the Materials module. Data from these modules is the used by the MatGen module to generate the system of equations. If PETSc is used, this data is then passed to the PETScMat and PETScVec modules, which are wrappers for the data library. These are then passed into the PETScKSP module which solves the problem. If PETSc isn't used, this data is passed into the CRS module, which stores the data efficiently, such that it can be fed into the Solver module. The solved data is then passed into the Output module, which generates an output both in .txt and .vtu format. This can also be represented through some blocks of pseudocode First read through the input file Open ( Input File ) Read Problem Data Read Material Data Close ( Input File ) Set Problem Data Set Material Data Then generate the equations and solve for the flux Get Problem Data Get Material Data do i = 1 , Problem Size Calculate Matrix Value Calculate Vector Value end do if ( PETSc Used ) then do i = 1 , Problem Size Fill PETSc Matrix Fill PETSc Vector end do Flux = PETScSolver ( PETSc Matrix , PETSc Vector ) else do i = 1 , Problem Size Fill CRS Matrix Fill Vector end do Flux = Solver ( CRS Matrix , Vector ) end if Finally generate the output files open ( Output File ) do i = 1 , Problem Size write ( Output File ) Position , Flux write ( Output File ) Region Number write ( Output File ) Node Number end do close ( Output File ) OOP in Fortran As discussed previously in the Introduction section, this code utilises Object Oriented Programming. An example of such an abject orented structure can be seen in the code snippet below. This shows some of the Materials module, which handles the storage of data pertaining the material properties of the problem. module Materials_Mod use Constants_Mod !!Stores standard material data and material data explicitly set via an input file implicit none type , public :: t_material private real ( kind = dp ) :: Sig_a , S character ( len = 20 ) :: Name contains !!Procedures which handle the storing, calculation and retrieval of material data procedure , public :: SetName => SetMaterialName procedure , public :: GetName => GetMaterialName procedure , public :: SetProps => SetMaterialProperties procedure , public :: GetSig_a procedure , public :: GetS end type We first define the name of the module such that it can be used by other modules in our code. module Materials_Mod We then tell our module to make use of the Constants module. use Constants_Mod This method of declaring the name of this specific module and the modules which this code can be seen throughout our various pieces of code. We would like to store some data within this module such that it can be called forth at a later date. As such, we set up a public type which contains our chosen private data. type , public :: t_material private real ( kind = dp ) :: Sig_a , S character ( len = 20 ) :: Name We can then also choose what public procedures this module should utilise, which other pieces of code can then utilise. The most common routines you will often utilise in a code are 'gets' and 'sets' which pull stored data and set stored data respectively. In fortran you can also utilise pointers to point to certain pieces of memory. A nice example of this can be seen in the code block below where SetName points to SetMaterialName allowing us to use quick subroutine names when repeatedly calling a routine, but verbose names within the actual module. procedure , public :: SetName => SetMaterialName procedure , public :: GetName => GetMaterialName procedure , public :: SetProps => SetMaterialProperties procedure , public :: GetSig_a procedure , public :: GetS end type","title":"2 - Object-Oriented Programming"},{"location":"2-oop/#2-object-oriented-programming","text":"","title":"2 - Object-Oriented Programming"},{"location":"2-oop/#introduction","text":"Object-Oriented Programming (OOP) is a method of coding by which a piece of software is designed around the different required data types and classes which will be used in the programme. In its simplest sense, this translates to a code which is made of multiple different modules which make use of one another, rather than one large block of code. This style of programming is particularly advantageous when working with large coding projects, such as those used in research or data science. OOP codes are also much easier to read once their structure has been understood. As such, this section of the readme will give an explanation of how the Diffusion Code project is structured. At its simplest level, the code reads a specified problem from an input file, converts that to a system of equations which can then be solved, and outputs the resulting data to a set of files which can be read by an external program such a GNUPlot or ParaView. \\text{Input File } \\rightarrow \\text{Generate Equations } \\rightarrow \\text{Solve } \\rightarrow \\text{Output File } This explanation can now be further expanded in terms of complexity, where the structure will be given in terms files and modules. For the sake of readability, this is given as a full flow chart below. The Problem module reads through the input file, storing relevant data or passing it to the Materials module. Data from these modules is the used by the MatGen module to generate the system of equations. If PETSc is used, this data is then passed to the PETScMat and PETScVec modules, which are wrappers for the data library. These are then passed into the PETScKSP module which solves the problem. If PETSc isn't used, this data is passed into the CRS module, which stores the data efficiently, such that it can be fed into the Solver module. The solved data is then passed into the Output module, which generates an output both in .txt and .vtu format. This can also be represented through some blocks of pseudocode First read through the input file Open ( Input File ) Read Problem Data Read Material Data Close ( Input File ) Set Problem Data Set Material Data Then generate the equations and solve for the flux Get Problem Data Get Material Data do i = 1 , Problem Size Calculate Matrix Value Calculate Vector Value end do if ( PETSc Used ) then do i = 1 , Problem Size Fill PETSc Matrix Fill PETSc Vector end do Flux = PETScSolver ( PETSc Matrix , PETSc Vector ) else do i = 1 , Problem Size Fill CRS Matrix Fill Vector end do Flux = Solver ( CRS Matrix , Vector ) end if Finally generate the output files open ( Output File ) do i = 1 , Problem Size write ( Output File ) Position , Flux write ( Output File ) Region Number write ( Output File ) Node Number end do close ( Output File )","title":"Introduction"},{"location":"2-oop/#oop-in-fortran","text":"As discussed previously in the Introduction section, this code utilises Object Oriented Programming. An example of such an abject orented structure can be seen in the code snippet below. This shows some of the Materials module, which handles the storage of data pertaining the material properties of the problem. module Materials_Mod use Constants_Mod !!Stores standard material data and material data explicitly set via an input file implicit none type , public :: t_material private real ( kind = dp ) :: Sig_a , S character ( len = 20 ) :: Name contains !!Procedures which handle the storing, calculation and retrieval of material data procedure , public :: SetName => SetMaterialName procedure , public :: GetName => GetMaterialName procedure , public :: SetProps => SetMaterialProperties procedure , public :: GetSig_a procedure , public :: GetS end type We first define the name of the module such that it can be used by other modules in our code. module Materials_Mod We then tell our module to make use of the Constants module. use Constants_Mod This method of declaring the name of this specific module and the modules which this code can be seen throughout our various pieces of code. We would like to store some data within this module such that it can be called forth at a later date. As such, we set up a public type which contains our chosen private data. type , public :: t_material private real ( kind = dp ) :: Sig_a , S character ( len = 20 ) :: Name We can then also choose what public procedures this module should utilise, which other pieces of code can then utilise. The most common routines you will often utilise in a code are 'gets' and 'sets' which pull stored data and set stored data respectively. In fortran you can also utilise pointers to point to certain pieces of memory. A nice example of this can be seen in the code block below where SetName points to SetMaterialName allowing us to use quick subroutine names when repeatedly calling a routine, but verbose names within the actual module. procedure , public :: SetName => SetMaterialName procedure , public :: GetName => GetMaterialName procedure , public :: SetProps => SetMaterialProperties procedure , public :: GetSig_a procedure , public :: GetS end type","title":"OOP in Fortran"},{"location":"3-compile-basics/","text":"3 - Compilation Basics Programming languages can be differentiated into Interpreted and Compiled languages. Languages such as Python are interpreted languages, where the code is read directly by the computer and the actions described are performed. In contrast, languages such as Fortran must be compiled by a program before the code can be used, where a program known as a compiler reads through the code, converting it to machine language. While time must be spent compiling the code, this generally results in very noticeable performance increases and is the reason why most high performance codes are compiled. Readers familiar with Python may be familiar with the numpy library that is often used for numerical calculations, a library which makes use of compiled codes to give Python codes some dramatic reductions in numerical computation time. Compiled Codes and CMake This project uses CMake for building and compiling. CMake is a tool commonly used for C/C++ and Fortran projects in order to allow for easy compilation of the project in multiple operating systems (Linux, OSX, Windows, etc.), using various compilers (GCC, Clang, Intel, etc.) with potentially different levels of optimisations (Debug, Release, etc.), all at the same time. The way CMake works is by reading a CMakeLists.txt file, which is a text file that contains the commands to be executed by CMake . CMake then scans for the project's dependencies and builds the necessary files e.g. Makefile s to compile the project. You then use the newly generated files to compile the project. A normal project being built with CMake will look something like this: mkdir build cd build cmake .. # This is relative to top level directory, containing CMakeLists.txt make all # Assuming we are using GNU Makefiles else use cmake --build . The greater discussion on build tools and more advanced forms of compilation is deferred for the later sections, see 7 - Build Tools . Build tools such as CMake are particularly useful in a compiled code that utilises OOP as it allows for easy compilation of the required files since it automatically deduces the order of dependencies, thus removing this burden from the programmer. The code snippet below comes from the CMakeLists.txt used in the project. set ( SOURCES src/Constants.F90 src/Materials.F90 src/Problem.F90 src/Output.F90 src/Matrix_Base.F90 src/CRS.F90 src/Solver.F90 src/MatGen.F90 ) Try and change the compilation order of the files in the SOURCES in CMakeLists.txt to see how the CMake can handle it gracefully. Run the following to reconfigure the project: cd build cmake .. make all The diffusion binary can be found under build/bin/diffusion and can be run with the following command: ./build/bin/diffusion NOTE: make sure you have an input.in file in the directory where you are running diffusion from. Debug and Release builds One of the most appealing features of CMake is the ability to build the project in different modes side-by-side. This allows for easy switching between different modes of compilation, e.g. Debug and Release. This project is by default built in Release mode, which enables various optimisations to make the code run faster. Let us try and build the project in Debug mode. From the root directory of the project run the following commands: mkdir debug cd debug cmake .. -DCMAKE_BUILD_TYPE = Debug make all That is all there is to it! The diffusion binary in the Debug build can be found under debug/bin/diffusion and can be run with like the normal diffusion binary. NOTE: make sure you have an input.in file in the directory where you are running diffusion from. Compiler Directives There will be instances where one might wish to pass certain options to the compiler, e.g. to disable a warning, or to enable some experimental optimisations or toggle a preprocessor macro. This can be done via the CMakeLists.txt file but also through the command-line interface of CMake . Here the latter is demonstrated. Say that in our Debug build we wish to disable the verbose debug output found in Solve.F90 #ifdef DEBUG ! If DEBUG macro is defined, then compile the following code write ( * , * ) \"---CG Convergence Succeeded---\" write ( * , '(g0)' , advance = 'no' ) \"Succeeded after iterations: \" write ( * , '(g0)' , advance = 'no' ) BCG_Iterations write ( * , '(g0)' , advance = 'no' ) \" with residual:\" write ( * , '(E14.6)' ) rho1 write ( * , * ) \"-------------------------------\" #endif As seen above, the #ifdef directive is used to enable or disable the code in the file. When we build the project in Debug mode, we also define the DEBUG preprocessor macro in our CMakeLists.txt . To prevent that snippet of code from compiling, normally we would pass the -UDEBUG option to the compiler. In CMake that can be achieved via cd debug cmake .. -DCMAKE_BUILD_TYPE = Debug -DCMAKE_Fortran_FLAGS = -UDEBUG make all To test that it worked run the following and observe that the output is missing the ---CG Convergence Succeeded--- ... lines ./debug/bin/diffusion NOTE: make sure you have an input.in file in the directory where you are running diffusion from.","title":"3 - Compilation Basics"},{"location":"3-compile-basics/#3-compilation-basics","text":"Programming languages can be differentiated into Interpreted and Compiled languages. Languages such as Python are interpreted languages, where the code is read directly by the computer and the actions described are performed. In contrast, languages such as Fortran must be compiled by a program before the code can be used, where a program known as a compiler reads through the code, converting it to machine language. While time must be spent compiling the code, this generally results in very noticeable performance increases and is the reason why most high performance codes are compiled. Readers familiar with Python may be familiar with the numpy library that is often used for numerical calculations, a library which makes use of compiled codes to give Python codes some dramatic reductions in numerical computation time.","title":"3 - Compilation Basics"},{"location":"3-compile-basics/#compiled-codes-and-cmake","text":"This project uses CMake for building and compiling. CMake is a tool commonly used for C/C++ and Fortran projects in order to allow for easy compilation of the project in multiple operating systems (Linux, OSX, Windows, etc.), using various compilers (GCC, Clang, Intel, etc.) with potentially different levels of optimisations (Debug, Release, etc.), all at the same time. The way CMake works is by reading a CMakeLists.txt file, which is a text file that contains the commands to be executed by CMake . CMake then scans for the project's dependencies and builds the necessary files e.g. Makefile s to compile the project. You then use the newly generated files to compile the project. A normal project being built with CMake will look something like this: mkdir build cd build cmake .. # This is relative to top level directory, containing CMakeLists.txt make all # Assuming we are using GNU Makefiles else use cmake --build . The greater discussion on build tools and more advanced forms of compilation is deferred for the later sections, see 7 - Build Tools . Build tools such as CMake are particularly useful in a compiled code that utilises OOP as it allows for easy compilation of the required files since it automatically deduces the order of dependencies, thus removing this burden from the programmer. The code snippet below comes from the CMakeLists.txt used in the project. set ( SOURCES src/Constants.F90 src/Materials.F90 src/Problem.F90 src/Output.F90 src/Matrix_Base.F90 src/CRS.F90 src/Solver.F90 src/MatGen.F90 ) Try and change the compilation order of the files in the SOURCES in CMakeLists.txt to see how the CMake can handle it gracefully. Run the following to reconfigure the project: cd build cmake .. make all The diffusion binary can be found under build/bin/diffusion and can be run with the following command: ./build/bin/diffusion NOTE: make sure you have an input.in file in the directory where you are running diffusion from.","title":"Compiled Codes and CMake"},{"location":"3-compile-basics/#debug-and-release-builds","text":"One of the most appealing features of CMake is the ability to build the project in different modes side-by-side. This allows for easy switching between different modes of compilation, e.g. Debug and Release. This project is by default built in Release mode, which enables various optimisations to make the code run faster. Let us try and build the project in Debug mode. From the root directory of the project run the following commands: mkdir debug cd debug cmake .. -DCMAKE_BUILD_TYPE = Debug make all That is all there is to it! The diffusion binary in the Debug build can be found under debug/bin/diffusion and can be run with like the normal diffusion binary. NOTE: make sure you have an input.in file in the directory where you are running diffusion from.","title":"Debug and Release builds"},{"location":"3-compile-basics/#compiler-directives","text":"There will be instances where one might wish to pass certain options to the compiler, e.g. to disable a warning, or to enable some experimental optimisations or toggle a preprocessor macro. This can be done via the CMakeLists.txt file but also through the command-line interface of CMake . Here the latter is demonstrated. Say that in our Debug build we wish to disable the verbose debug output found in Solve.F90 #ifdef DEBUG ! If DEBUG macro is defined, then compile the following code write ( * , * ) \"---CG Convergence Succeeded---\" write ( * , '(g0)' , advance = 'no' ) \"Succeeded after iterations: \" write ( * , '(g0)' , advance = 'no' ) BCG_Iterations write ( * , '(g0)' , advance = 'no' ) \" with residual:\" write ( * , '(E14.6)' ) rho1 write ( * , * ) \"-------------------------------\" #endif As seen above, the #ifdef directive is used to enable or disable the code in the file. When we build the project in Debug mode, we also define the DEBUG preprocessor macro in our CMakeLists.txt . To prevent that snippet of code from compiling, normally we would pass the -UDEBUG option to the compiler. In CMake that can be achieved via cd debug cmake .. -DCMAKE_BUILD_TYPE = Debug -DCMAKE_Fortran_FLAGS = -UDEBUG make all To test that it worked run the following and observe that the output is missing the ---CG Convergence Succeeded--- ... lines ./debug/bin/diffusion NOTE: make sure you have an input.in file in the directory where you are running diffusion from.","title":"Compiler Directives"},{"location":"4-io/","text":"4 - File I/O Operations Reading input data from file Scientific codes will often make use of an input file which contains the problem specification. These codes must therefore be able to open an input file and read through it, extracting the relevant data such that it can be used to solve the problem. This can be seen in the code snippet below taken from the Problem module, where an input file has been opened, and the boundary conditions read in. !!Open input file containing problem specification open ( InputFile , File = 'input.in' , Status = 'Old' ) !!Read in the boundary conditions of the problem String_Read = '' do while ( String_Read . ne . 'Boundary_Conditions:' ) read ( InputFile , * ) String_Read end do do ii = 1 , 2 read ( InputFile , * ) String_Read if ( String_Read == 'Zero' ) then this % Boundary_Conditions ( ii ) = 0 else if ( String_Read == 'Reflective' ) then this % Boundary_Conditions ( ii ) = 1 else write ( * , * ) \"ERROR: Unrecognised Boundary Condition\" end if end do When reading an input file, Fortran needs an Integer ID, Filename and Status. The ID allows the file to be referred to easily in future, and is good practice to set through a parameter for readability. The Filename simply matches the name of the file, and the status describes the state of the file, in this case it is an 'Old' file which already exists in the directory. integer , parameter :: InputFile = 101 open ( InputFile , file = 'input.in' , status = 'Old' ) We then wish to read through our file until we reach the name of the boundary conditions. To do so, we loop through our file until we reach the 'Boundary_Conditions:' string. We now know that the next line will contain the name of our boundary condition, and hence this can be read in. String_Read = '' String_Read = '' do while ( String_Read /= 'Boundary_Conditions:' ) read ( InputFile , * ) String_Read end do We finally need to check what type of boundary has been specified and store this information. Here we have an If statement which will loop over the known boundary condition names. Read ( InputFile , * ) String_Read if ( String_Read == 'Zero' ) then this % Boundary_Conditions ( ii ) = 0 else if ( String_Read == 'Reflective' ) then this % Boundary_Conditions ( ii ) = 1 else write ( * , * ) \"ERROR: Unrecognised Boundary Condition\" end if Finally, we should close this file, achieved through the close command and the associated ID. close ( InputFile ) Generating output files Most scientific codes will want to generate outputs that can be read by external software such as GNUPlot. To do so, data generated by the code must be written to an output file in some given format. This is done in a way similar to that of reading the input, with the read statements replaced with write statements. First we tell the code to open the output file, specifying 'Replace' to tell the code that we wish to overwrite the file if it is already present. !!Generate textfile open ( textfile , File = 'OutputFile.txt' , Status = 'Replace' ) We then loop over our solutions, writing the values of the position and fluxes to the text file, with each row corresponding to a node. In code snippet below we write down the data for the first node, then loop over the rest of the nodes in each of the regions. Position = 0._dp !!First node NodeID = 1 write ( textfile , '(2E14.6)' ) Position , Flux ( NodeID ) do ii = 1 , N_Regions do jj = 1 , RegionNodes ( ii ) - 1 NodeID = NodeID + 1 Position = Position + ( Boundary_Pos ( ii + 1 ) - Boundary_Pos ( ii )) / Real ( RegionNodes ( ii ) - 1 , dp ) write ( textfile , '(2E14.6)' ) Position , Flux ( NodeID ) end do end do Finally, we close the file. We now have a complete set of output data stored in text format that can be plotted or used for later analysis. close ( textfile )","title":"4 - File I/O Operations"},{"location":"4-io/#4-file-io-operations","text":"","title":"4 - File I/O Operations"},{"location":"4-io/#reading-input-data-from-file","text":"Scientific codes will often make use of an input file which contains the problem specification. These codes must therefore be able to open an input file and read through it, extracting the relevant data such that it can be used to solve the problem. This can be seen in the code snippet below taken from the Problem module, where an input file has been opened, and the boundary conditions read in. !!Open input file containing problem specification open ( InputFile , File = 'input.in' , Status = 'Old' ) !!Read in the boundary conditions of the problem String_Read = '' do while ( String_Read . ne . 'Boundary_Conditions:' ) read ( InputFile , * ) String_Read end do do ii = 1 , 2 read ( InputFile , * ) String_Read if ( String_Read == 'Zero' ) then this % Boundary_Conditions ( ii ) = 0 else if ( String_Read == 'Reflective' ) then this % Boundary_Conditions ( ii ) = 1 else write ( * , * ) \"ERROR: Unrecognised Boundary Condition\" end if end do When reading an input file, Fortran needs an Integer ID, Filename and Status. The ID allows the file to be referred to easily in future, and is good practice to set through a parameter for readability. The Filename simply matches the name of the file, and the status describes the state of the file, in this case it is an 'Old' file which already exists in the directory. integer , parameter :: InputFile = 101 open ( InputFile , file = 'input.in' , status = 'Old' ) We then wish to read through our file until we reach the name of the boundary conditions. To do so, we loop through our file until we reach the 'Boundary_Conditions:' string. We now know that the next line will contain the name of our boundary condition, and hence this can be read in. String_Read = '' String_Read = '' do while ( String_Read /= 'Boundary_Conditions:' ) read ( InputFile , * ) String_Read end do We finally need to check what type of boundary has been specified and store this information. Here we have an If statement which will loop over the known boundary condition names. Read ( InputFile , * ) String_Read if ( String_Read == 'Zero' ) then this % Boundary_Conditions ( ii ) = 0 else if ( String_Read == 'Reflective' ) then this % Boundary_Conditions ( ii ) = 1 else write ( * , * ) \"ERROR: Unrecognised Boundary Condition\" end if Finally, we should close this file, achieved through the close command and the associated ID. close ( InputFile )","title":"Reading input data from file"},{"location":"4-io/#generating-output-files","text":"Most scientific codes will want to generate outputs that can be read by external software such as GNUPlot. To do so, data generated by the code must be written to an output file in some given format. This is done in a way similar to that of reading the input, with the read statements replaced with write statements. First we tell the code to open the output file, specifying 'Replace' to tell the code that we wish to overwrite the file if it is already present. !!Generate textfile open ( textfile , File = 'OutputFile.txt' , Status = 'Replace' ) We then loop over our solutions, writing the values of the position and fluxes to the text file, with each row corresponding to a node. In code snippet below we write down the data for the first node, then loop over the rest of the nodes in each of the regions. Position = 0._dp !!First node NodeID = 1 write ( textfile , '(2E14.6)' ) Position , Flux ( NodeID ) do ii = 1 , N_Regions do jj = 1 , RegionNodes ( ii ) - 1 NodeID = NodeID + 1 Position = Position + ( Boundary_Pos ( ii + 1 ) - Boundary_Pos ( ii )) / Real ( RegionNodes ( ii ) - 1 , dp ) write ( textfile , '(2E14.6)' ) Position , Flux ( NodeID ) end do end do Finally, we close the file. We now have a complete set of output data stored in text format that can be plotted or used for later analysis. close ( textfile )","title":"Generating output files"},{"location":"5-visualisation/","text":"5 - Data Visualisation The 1D diffusion solver is computing the neutron transport equation and outputs the solution i.e. flux into a file. Here a few noteworthy methods of visualising the solution are discussed, ranging from easy-to-use, low level applications, to 3D interactive visualisation programs. gnuplot gnuplot is an easy to use, yet very versatile command-line plotting tool that is common in scientific computing. In Ubuntu - Linux one can install gnuplot via: sudo apt update sudo apt install gnuplot -y For installation on Windows, you can download gnuplot from: http://www.gnuplot.info/download.html . Alternatively, you can try and use Anaconda to install the package. conda install -c conda-forge gnuplot A small script by the name fluxplot in the tools directory is provided to help generate the figure in gnuplot. The plot can be generated with the command: gnuplot -p tools/fluxplot Python Another very common way of visualising data is with Python and the matplotlib library. The data output from the code is in the form of a space-delimited file which can easily be read into Python using the numpy library. A small script by the name plot.py in the tools directory is provided to help generate the figure in Python. python3 tools/plot.py ParaView One particular output viewing software that may be of interest to some readers is ParaView. ParaView is a widely used software for data analysis and visualisation within the scientific community. While ParaView could read in our text file outputs to generate a graph, this does not demonstrate much of the power of the software. Instead, the code has been written such that it will generate a 2-Dimensional plot of the flux that can be manipulated in ParaView. To download ParaView please visit https://www.paraview.org/download/ , while a user guide for ParaView can be found at: https://docs.paraview.org/en/latest/ ParaView is capable of reading various file formats. In this exemplar we will be focusing on generate an output file which uses the VTK ASCII file format. We have also made use of the more modern .vtu file type, a form of VTK file which makes use of an XML file structure. In addition to the readability we gain from such a structure, it is also recommended that users avoid the .vtk legacy file type if possible. A snippet from OutputFile.vtu can be seen below, where we have specified that this is a VTKFile using the Unstructured Grid format. Contained within the Unstructured Grid, we define the number of points and cells within the problem. We then go on to describe the relevant point and cell data . The VTK file format is described in more detail here . <?xml version=\"1.0\"?> <VTKFile type= \"UnstructuredGrid\" version= \"0.1\" byte_order= \"LittleEndian\" > <UnstructuredGrid> <Piece NumberOfPoints= \"18\" NumberOfCells= \"8\" ></Piece></UnstructuredGrid> </VTKFile> To load a file into ParaView you can either use the Open menu inside ParaView, or from a terminal you can use the command: paraview OutputFile.vtu","title":"5 - Data Visualisation"},{"location":"5-visualisation/#5-data-visualisation","text":"The 1D diffusion solver is computing the neutron transport equation and outputs the solution i.e. flux into a file. Here a few noteworthy methods of visualising the solution are discussed, ranging from easy-to-use, low level applications, to 3D interactive visualisation programs.","title":"5 - Data Visualisation"},{"location":"5-visualisation/#gnuplot","text":"gnuplot is an easy to use, yet very versatile command-line plotting tool that is common in scientific computing. In Ubuntu - Linux one can install gnuplot via: sudo apt update sudo apt install gnuplot -y For installation on Windows, you can download gnuplot from: http://www.gnuplot.info/download.html . Alternatively, you can try and use Anaconda to install the package. conda install -c conda-forge gnuplot A small script by the name fluxplot in the tools directory is provided to help generate the figure in gnuplot. The plot can be generated with the command: gnuplot -p tools/fluxplot","title":"gnuplot"},{"location":"5-visualisation/#python","text":"Another very common way of visualising data is with Python and the matplotlib library. The data output from the code is in the form of a space-delimited file which can easily be read into Python using the numpy library. A small script by the name plot.py in the tools directory is provided to help generate the figure in Python. python3 tools/plot.py","title":"Python"},{"location":"5-visualisation/#paraview","text":"One particular output viewing software that may be of interest to some readers is ParaView. ParaView is a widely used software for data analysis and visualisation within the scientific community. While ParaView could read in our text file outputs to generate a graph, this does not demonstrate much of the power of the software. Instead, the code has been written such that it will generate a 2-Dimensional plot of the flux that can be manipulated in ParaView. To download ParaView please visit https://www.paraview.org/download/ , while a user guide for ParaView can be found at: https://docs.paraview.org/en/latest/ ParaView is capable of reading various file formats. In this exemplar we will be focusing on generate an output file which uses the VTK ASCII file format. We have also made use of the more modern .vtu file type, a form of VTK file which makes use of an XML file structure. In addition to the readability we gain from such a structure, it is also recommended that users avoid the .vtk legacy file type if possible. A snippet from OutputFile.vtu can be seen below, where we have specified that this is a VTKFile using the Unstructured Grid format. Contained within the Unstructured Grid, we define the number of points and cells within the problem. We then go on to describe the relevant point and cell data . The VTK file format is described in more detail here . <?xml version=\"1.0\"?> <VTKFile type= \"UnstructuredGrid\" version= \"0.1\" byte_order= \"LittleEndian\" > <UnstructuredGrid> <Piece NumberOfPoints= \"18\" NumberOfCells= \"8\" ></Piece></UnstructuredGrid> </VTKFile> To load a file into ParaView you can either use the Open menu inside ParaView, or from a terminal you can use the command: paraview OutputFile.vtu","title":"ParaView"},{"location":"6-sparse-storage/","text":"6 - Optimised data storage In addition to using faster codes such as Fortran, we can also achieve some significant speed increases by being careful with our use of memory. One important optimisation in our code will be how we store the data in our matrix A . The matrix A for a 3-node and 5-node system can be seen below, where a , b and c are our lower, main and upper diagonals respectively. We can already begin to see that we are storing a large portion of 0 's in our system, a problem which will only increase as we increase our node numbers by orders of magnitude. \\left(\\begin{array}{ccc} b & c & 0\\\\ a & b & c\\\\ 0 & a & b\\\\ \\end{array}\\right) \\rightarrow \\left(\\begin{array}{ccccc} b & c & 0 & 0 & 0\\\\ a & b & c & 0 & 0\\\\ 0 & a & b & c & 0\\\\ 0 & 0 & a & b & c\\\\ 0 & 0 & 0 & a & b\\\\ \\end{array}\\right) These matrices are known as 'sparse', as much of the data that they contain is of value 0 . We can therefore drastically reduce the amount of memory needed to store this matrix by only saving the values and the positions that they occupy. A number of efficient storage systems exist for this problem, but we have chosen to use Compressed Row Storage (CRS) in this case as it makes no assumptions about the structure of the matrix and can therefore be applied to a large range of problems. A good explanation of this methodology can be found at http://netlib.org/linalg/html_templates/node91.html .","title":"6 - Optimised data storage"},{"location":"6-sparse-storage/#6-optimised-data-storage","text":"In addition to using faster codes such as Fortran, we can also achieve some significant speed increases by being careful with our use of memory. One important optimisation in our code will be how we store the data in our matrix A . The matrix A for a 3-node and 5-node system can be seen below, where a , b and c are our lower, main and upper diagonals respectively. We can already begin to see that we are storing a large portion of 0 's in our system, a problem which will only increase as we increase our node numbers by orders of magnitude. \\left(\\begin{array}{ccc} b & c & 0\\\\ a & b & c\\\\ 0 & a & b\\\\ \\end{array}\\right) \\rightarrow \\left(\\begin{array}{ccccc} b & c & 0 & 0 & 0\\\\ a & b & c & 0 & 0\\\\ 0 & a & b & c & 0\\\\ 0 & 0 & a & b & c\\\\ 0 & 0 & 0 & a & b\\\\ \\end{array}\\right) These matrices are known as 'sparse', as much of the data that they contain is of value 0 . We can therefore drastically reduce the amount of memory needed to store this matrix by only saving the values and the positions that they occupy. A number of efficient storage systems exist for this problem, but we have chosen to use Compressed Row Storage (CRS) in this case as it makes no assumptions about the structure of the matrix and can therefore be applied to a large range of problems. A good explanation of this methodology can be found at http://netlib.org/linalg/html_templates/node91.html .","title":"6 - Optimised data storage"},{"location":"7-build-tools/","text":"7 - Build Tools CMake We have already briefly discussed the use of CMake in the previous section 3 - Compilation Basics . More specifically we have covered: Building the project Compiling the project Building multiple configurations (Debug, Release) Passing options to the compiler, e.g. to disable a warning, or a preprocessor macro In this section we will cover some additional aspects of CMake Peeking into the CMakeLists.txt and CMake syntax Enabling/disabling settings Find external libraries High level UI using ccmake and cmake-gui Anatomy of CMakeLists.txt It is now time to peek into the CMakeLists.txt file and try and understand the syntax. CMkake relies on a relatively simple syntax with extensive online documentation, which you can view here . It is based around the concept of creating targets and then configuring the properties of the targets. For example, the diffusion binary is defined as an executable target. cmake_minimum_required ( VERSION 3.13 ) project ( diffusion ) enable_language ( Fortran ) set ( BIN_NAME diffusion ) # define a variable with name BIN_NAME set ( SOURCES # define a list with all the source file names src/Constants.F90 src/Materials.F90 src/Problem.F90 src/Output.F90 src/Matrix_Base.F90 src/CRS.F90 src/Solver.F90 src/MatGen.F90 ) # create a target with name BIN_NAME from files SOURCES + main.F90 add_executable ( ${ BIN_NAME } ${ SOURCES } app/main.F90 ) The above snippet is enough to instruct cmake to compile the sources into an executable. Additional properties to a target e.g. it's output name, output location, etc. can be configured by using the set_target_properties command. # Set additional properties for executable target set_target_properties ( ${ BIN_NAME } # this is the target's name PROPERTIES OUTPUT_NAME ${ PROJECT_NAME } # use the project name for the binary RUNTIME_OUTPUT_DIRECTORY ${ CMAKE_BINARY_DIR } /bin # put binary in build/bin/ Fortran_MODULE_DIRECTORY ${ CMAKE_BINARY_DIR } /src ) # put .mod in build/src/ Properties can also be set for the installation process. # by default installs to CMAKE_INSTALL_PREFIX # you can override the behaviour by setting the variable to something similar to # set(CMAKE_INSTALL_PREFIX ${CMAKE_CURRENT_SOURCE_DIR}/install CACHE STRING \"\") # which would create an install folder in the root directory of the project. set ( INSTALL_BIN_DIR \"bin\" ) # install the executable: specify the install location install ( TARGETS ${ BIN_NAME } RUNTIME DESTINATION ${ INSTALL_BIN_DIR } ARCHIVE DESTINATION ${ INSTALL_BIN_DIR } ) Adding and toggling settings As a project grows in complexity, often times you might want to define some custom options, that turn on/off certain features, adds a compiler flag, ignores certain source files etc. This can be done in cmake by using the option keyword. Say that you have certain source files that you want to be able to compile, but you don't want to do so by default, in this case the solutions to the exemplar exercises. You can create the following option # defines a variable called BUILD_SOLUTIONS option ( BUILD_SOLUTIONS \"Build the exemplar's solutions\" OFF ) ... if ( BUILD_SOLUTIONS ) # compile the solutions only if BUILD_SOLUTIONS is ON ... endif () To toggle the settings of cmake without having to modify the CMakeLists.txt file, similarly to building multiple configurations (Debug and Release) by passing a command line option to cmake , in a terminal on would do cmake .. -DBUILD_SOLUTIONS = ON # from within the build/ Finding external libraries Many times you will want to incorporate an external library into your project to add certain functionality. For example, you might want to include a linear algebra library to make mathematical operations on matrices easier. CMake offers a way to find these libraries via the pkg_search_module find_package ( PkgConfig ) # enable the pkg_search_module # look for library called libname and prefix all variables with MY_VAR_PREFIX pkg_search_module ( MY_VAR_PREFIX REQUIRED IMPORTED_TARGET libname ) High level GUI using ccmake and cmake-gui ccmake is a command line User Interface (UI) meant to be used to interactively toggle project configuration settings. You can launch ccmake after you have configured your project via cmake .. # from within build/ ccmake . From ccmake you can then toggle settings and even expose all the predefined cmake variables (by pressing t ), reconfigure the project (by pressing c ), read the help menus (by pressing h ) and much more. Similarly to the command line interface there is also a graphical interface cmake-gui which can perform the identical tasks. You can launch cmake-gui after you have configured your project via cmake .. # from within build/ cmake-gui .. For more information on cmake make sure to read the online documentation . You can also try and go through the CMakeLists.txt file provided in this project. It is well documented and uses various different features of cmake . Feel free to also use it as a template for your own projects. FPM - Fortran Package Manager FPM stands for the Fortran Package Manager, and it is meant to be an easy-to-use build and compilation tool, serving as an alternative to more complicated build tools like CMake or Make . Automatically, fpm assumes by default that the Fortran source files are in: src/ for modules and procedure source app/ main program(s) for applications test/ main program(s) and support files for project tests example/ main program(s) for example programs Any additional settings can be specified in the fpm.toml configuration file. name = \"diffusion\" version = \"1.0.0\" [build] auto-tests = false auto-examples = false auto-executables = false external-modules = [ \"petscsys\" , \"petscksp\" , \"petscvec\" , \"petscmat\" ] [library] source-dir = \"src\" [[executable]] name = \"diffusion\" source-dir = \"app\" main = \"main.F90\" link = [ \"petsc\" ] To demonstrate how simple it is to build using fpm , we will build this project alongside cmake by running: fpm build To run the program you can instruct fpm to do it for you by running: fpm run Or install it to a directory by running: fpm install --prefix = ./install Additional flags to the Fortran compile can be passed with the --flag option fpm run --flag \"-DDEBUG\" For more information on how to use FPM, see the FPM documentation and the FPM manifest","title":"7 - Build Tools"},{"location":"7-build-tools/#7-build-tools","text":"","title":"7 - Build Tools"},{"location":"7-build-tools/#cmake","text":"We have already briefly discussed the use of CMake in the previous section 3 - Compilation Basics . More specifically we have covered: Building the project Compiling the project Building multiple configurations (Debug, Release) Passing options to the compiler, e.g. to disable a warning, or a preprocessor macro In this section we will cover some additional aspects of CMake Peeking into the CMakeLists.txt and CMake syntax Enabling/disabling settings Find external libraries High level UI using ccmake and cmake-gui","title":"CMake"},{"location":"7-build-tools/#anatomy-of-cmakeliststxt","text":"It is now time to peek into the CMakeLists.txt file and try and understand the syntax. CMkake relies on a relatively simple syntax with extensive online documentation, which you can view here . It is based around the concept of creating targets and then configuring the properties of the targets. For example, the diffusion binary is defined as an executable target. cmake_minimum_required ( VERSION 3.13 ) project ( diffusion ) enable_language ( Fortran ) set ( BIN_NAME diffusion ) # define a variable with name BIN_NAME set ( SOURCES # define a list with all the source file names src/Constants.F90 src/Materials.F90 src/Problem.F90 src/Output.F90 src/Matrix_Base.F90 src/CRS.F90 src/Solver.F90 src/MatGen.F90 ) # create a target with name BIN_NAME from files SOURCES + main.F90 add_executable ( ${ BIN_NAME } ${ SOURCES } app/main.F90 ) The above snippet is enough to instruct cmake to compile the sources into an executable. Additional properties to a target e.g. it's output name, output location, etc. can be configured by using the set_target_properties command. # Set additional properties for executable target set_target_properties ( ${ BIN_NAME } # this is the target's name PROPERTIES OUTPUT_NAME ${ PROJECT_NAME } # use the project name for the binary RUNTIME_OUTPUT_DIRECTORY ${ CMAKE_BINARY_DIR } /bin # put binary in build/bin/ Fortran_MODULE_DIRECTORY ${ CMAKE_BINARY_DIR } /src ) # put .mod in build/src/ Properties can also be set for the installation process. # by default installs to CMAKE_INSTALL_PREFIX # you can override the behaviour by setting the variable to something similar to # set(CMAKE_INSTALL_PREFIX ${CMAKE_CURRENT_SOURCE_DIR}/install CACHE STRING \"\") # which would create an install folder in the root directory of the project. set ( INSTALL_BIN_DIR \"bin\" ) # install the executable: specify the install location install ( TARGETS ${ BIN_NAME } RUNTIME DESTINATION ${ INSTALL_BIN_DIR } ARCHIVE DESTINATION ${ INSTALL_BIN_DIR } )","title":"Anatomy of CMakeLists.txt"},{"location":"7-build-tools/#adding-and-toggling-settings","text":"As a project grows in complexity, often times you might want to define some custom options, that turn on/off certain features, adds a compiler flag, ignores certain source files etc. This can be done in cmake by using the option keyword. Say that you have certain source files that you want to be able to compile, but you don't want to do so by default, in this case the solutions to the exemplar exercises. You can create the following option # defines a variable called BUILD_SOLUTIONS option ( BUILD_SOLUTIONS \"Build the exemplar's solutions\" OFF ) ... if ( BUILD_SOLUTIONS ) # compile the solutions only if BUILD_SOLUTIONS is ON ... endif () To toggle the settings of cmake without having to modify the CMakeLists.txt file, similarly to building multiple configurations (Debug and Release) by passing a command line option to cmake , in a terminal on would do cmake .. -DBUILD_SOLUTIONS = ON # from within the build/","title":"Adding and toggling settings"},{"location":"7-build-tools/#finding-external-libraries","text":"Many times you will want to incorporate an external library into your project to add certain functionality. For example, you might want to include a linear algebra library to make mathematical operations on matrices easier. CMake offers a way to find these libraries via the pkg_search_module find_package ( PkgConfig ) # enable the pkg_search_module # look for library called libname and prefix all variables with MY_VAR_PREFIX pkg_search_module ( MY_VAR_PREFIX REQUIRED IMPORTED_TARGET libname )","title":"Finding external libraries"},{"location":"7-build-tools/#high-level-gui-using-ccmake-and-cmake-gui","text":"ccmake is a command line User Interface (UI) meant to be used to interactively toggle project configuration settings. You can launch ccmake after you have configured your project via cmake .. # from within build/ ccmake . From ccmake you can then toggle settings and even expose all the predefined cmake variables (by pressing t ), reconfigure the project (by pressing c ), read the help menus (by pressing h ) and much more. Similarly to the command line interface there is also a graphical interface cmake-gui which can perform the identical tasks. You can launch cmake-gui after you have configured your project via cmake .. # from within build/ cmake-gui .. For more information on cmake make sure to read the online documentation . You can also try and go through the CMakeLists.txt file provided in this project. It is well documented and uses various different features of cmake . Feel free to also use it as a template for your own projects.","title":"High level GUI using ccmake and cmake-gui"},{"location":"7-build-tools/#fpm-fortran-package-manager","text":"FPM stands for the Fortran Package Manager, and it is meant to be an easy-to-use build and compilation tool, serving as an alternative to more complicated build tools like CMake or Make . Automatically, fpm assumes by default that the Fortran source files are in: src/ for modules and procedure source app/ main program(s) for applications test/ main program(s) and support files for project tests example/ main program(s) for example programs Any additional settings can be specified in the fpm.toml configuration file. name = \"diffusion\" version = \"1.0.0\" [build] auto-tests = false auto-examples = false auto-executables = false external-modules = [ \"petscsys\" , \"petscksp\" , \"petscvec\" , \"petscmat\" ] [library] source-dir = \"src\" [[executable]] name = \"diffusion\" source-dir = \"app\" main = \"main.F90\" link = [ \"petsc\" ] To demonstrate how simple it is to build using fpm , we will build this project alongside cmake by running: fpm build To run the program you can instruct fpm to do it for you by running: fpm run Or install it to a directory by running: fpm install --prefix = ./install Additional flags to the Fortran compile can be passed with the --flag option fpm run --flag \"-DDEBUG\" For more information on how to use FPM, see the FPM documentation and the FPM manifest","title":"FPM - Fortran Package Manager"},{"location":"8-ext-libs/","text":"8 - Using External Libraries While we can make many efforts to write our own optimised data storage and solver routines, a number of libraries exist which will do this far more optimally. In many cases, people will have spent huge amounts of time to write libraries that can perform an action as efficiently as possible, so it is sensible for us to expect their routines to provide a performance increase when compared to ours. For some smaller routines, you will often be able to find optimal examples shared online, but for larger problems you will often need to incorporate a whole library. In our code, we have facilitated the use of the 'Portable, Extensible Toolkit for Scientific Computation' (PETSc). Installing and using this library is explained in the respective Installation and Compilation sections. When using an external library, we will generally have to write a 'wrapper' in our code, which provides an interface between our own routines and the routines of the library. An example of this is shown in the code snippets below for the PETSc_Init module, which initialises the PETSc library. We first create our module and use the #include statements to tell the code to use our main path specified in our makefile and then look for this specific file petscsys.h . We then tell it to use petscsys , allowing us to perform actions which require this file, such as initialising PETSc. module PETSc_Init_Mod !!Initialize the PETSc Database #include <petsc/finclude/petscsys.h> use petscsys We then write our subroutine which does the actual initialisation, PETSc_Init . We check if the routine has been called already and if not we call PETScInitialize , a routine of the PETSc library. This sets up PETSc such that we can now define our relevant vectors or matrices and then solve the system of equations. Subroutine PETSc_Init PetscErrorCode ierr logical :: Called = . false . if (. not . Called ) then Call PetscInitialize ( PETSC_NULL_CHARACTER , ierr ) Called = . true . if ( ierr /= 0 ) error stop \"Failed to Initialize PETSc\" end if end subroutine PETSc_Init Installing PETSc The Portable, Extensible Toolkit for Scientific Computation (PETSc) is an optional external library which can be utilised in this problem to solve the system of equations generated by the code. This section will give an explanation of how to download and compile PETSc. Note that the configuring and testing of PETSc may take some time. Installation instructions can also be found at https://petsc.org/release/install/ Download a copy of PETSc from: https://petsc.org/release/download/ Place the downloaded PETSc folder into the directory of your choice and navigate inside it through a terminal. Configure the code by running: ./configure --download-mpich --download-fblaslapack = 1 --prefix = recode Check that the installation was successful by running: make check NOTE: save the PETSC_DIR and PETSC_ARCH variables for later, you will be needing them! Compiling with PETSc With PETSc installed on your system, the last stage is to set up the environment variables that point to the installation of PETSc. In a terminal copy and paste the following commands but using your own PETSC_DIR and PETSC_ARCH values from before! export PETSC_DIR = \"/home/jack/petsc-3.16.0\" export PETSC_ARCH = \"recode\" Once you have installed PETSc (see installation instructions ) and set up the required environment variables, the code can also be compiled to use it instead of the custom storage and solvers. CMake Using cmake this can be done by navigating to the build directory and running the following command: cmake .. -DUSE_PETSC = ON make all make install This should create in the project root the install/bin/diffusion executable, which can be run via ./install/bin/diffusion FPM - Fortran Package Manager FPM again is noticeably simpler than cmake . To compile using PETSc in a terminal just type: fpm run --flag \"-DPETSC -I ${ PETSC_DIR } /include -I ${ PETSC_DIR } / ${ PETSC_ARCH } /include\" --link-flag \"-L ${ PETSC_DIR } / ${ PETSC_ARCH } /lib\" Project is up to date >Input Read >Matrices Created >Problem Assembled >Output Generated >Problem Solved in: 0.658860E-01 seconds The additional arguments are flags that are passed to the compiler and the linker to ensure that the PETSc libraries are included and linked correctly.","title":"8 - Using External Libraries"},{"location":"8-ext-libs/#8-using-external-libraries","text":"While we can make many efforts to write our own optimised data storage and solver routines, a number of libraries exist which will do this far more optimally. In many cases, people will have spent huge amounts of time to write libraries that can perform an action as efficiently as possible, so it is sensible for us to expect their routines to provide a performance increase when compared to ours. For some smaller routines, you will often be able to find optimal examples shared online, but for larger problems you will often need to incorporate a whole library. In our code, we have facilitated the use of the 'Portable, Extensible Toolkit for Scientific Computation' (PETSc). Installing and using this library is explained in the respective Installation and Compilation sections. When using an external library, we will generally have to write a 'wrapper' in our code, which provides an interface between our own routines and the routines of the library. An example of this is shown in the code snippets below for the PETSc_Init module, which initialises the PETSc library. We first create our module and use the #include statements to tell the code to use our main path specified in our makefile and then look for this specific file petscsys.h . We then tell it to use petscsys , allowing us to perform actions which require this file, such as initialising PETSc. module PETSc_Init_Mod !!Initialize the PETSc Database #include <petsc/finclude/petscsys.h> use petscsys We then write our subroutine which does the actual initialisation, PETSc_Init . We check if the routine has been called already and if not we call PETScInitialize , a routine of the PETSc library. This sets up PETSc such that we can now define our relevant vectors or matrices and then solve the system of equations. Subroutine PETSc_Init PetscErrorCode ierr logical :: Called = . false . if (. not . Called ) then Call PetscInitialize ( PETSC_NULL_CHARACTER , ierr ) Called = . true . if ( ierr /= 0 ) error stop \"Failed to Initialize PETSc\" end if end subroutine PETSc_Init","title":"8 - Using External Libraries"},{"location":"8-ext-libs/#installing-petsc","text":"The Portable, Extensible Toolkit for Scientific Computation (PETSc) is an optional external library which can be utilised in this problem to solve the system of equations generated by the code. This section will give an explanation of how to download and compile PETSc. Note that the configuring and testing of PETSc may take some time. Installation instructions can also be found at https://petsc.org/release/install/ Download a copy of PETSc from: https://petsc.org/release/download/ Place the downloaded PETSc folder into the directory of your choice and navigate inside it through a terminal. Configure the code by running: ./configure --download-mpich --download-fblaslapack = 1 --prefix = recode Check that the installation was successful by running: make check NOTE: save the PETSC_DIR and PETSC_ARCH variables for later, you will be needing them!","title":"Installing PETSc"},{"location":"8-ext-libs/#compiling-with-petsc","text":"With PETSc installed on your system, the last stage is to set up the environment variables that point to the installation of PETSc. In a terminal copy and paste the following commands but using your own PETSC_DIR and PETSC_ARCH values from before! export PETSC_DIR = \"/home/jack/petsc-3.16.0\" export PETSC_ARCH = \"recode\" Once you have installed PETSc (see installation instructions ) and set up the required environment variables, the code can also be compiled to use it instead of the custom storage and solvers.","title":"Compiling with PETSc"},{"location":"8-ext-libs/#cmake","text":"Using cmake this can be done by navigating to the build directory and running the following command: cmake .. -DUSE_PETSC = ON make all make install This should create in the project root the install/bin/diffusion executable, which can be run via ./install/bin/diffusion","title":"CMake"},{"location":"8-ext-libs/#fpm-fortran-package-manager","text":"FPM again is noticeably simpler than cmake . To compile using PETSc in a terminal just type: fpm run --flag \"-DPETSC -I ${ PETSC_DIR } /include -I ${ PETSC_DIR } / ${ PETSC_ARCH } /include\" --link-flag \"-L ${ PETSC_DIR } / ${ PETSC_ARCH } /lib\" Project is up to date >Input Read >Matrices Created >Problem Assembled >Output Generated >Problem Solved in: 0.658860E-01 seconds The additional arguments are flags that are passed to the compiler and the linker to ensure that the PETSc libraries are included and linked correctly.","title":"FPM - Fortran Package Manager"},{"location":"appendix/","text":"Appendix A - Theory Neutron Diffusion Theory In the design of any nuclear reactor, it is critical to understand the distribution of neutrons throughout the system. As neutrons move through various parts of the reactor such as the fuel or the moderator, their behaviour will greatly change based on the medium in which they find themselves. This neutron behaviour can be most simply approximated as a form of diffusion occurring within the reactor, producing a solvable equation which can be used to accurately describe this behaviour. The analysis and solving of this equation is known as neutron diffusion theory, and is a critical area of nuclear physics and engineering, used widely in the industry to calculate neutron flux profiles and multiplication factors within a reactor. The first step in generating this equation is to describe the spatial neutron balance within a volume dV , where dV = dx dy dz , centred at r , where r = (x,y,z) . Assuming steady state: \\text{neutrons lost in } dV/s = \\text{neutrons produced in } dV/s Splitting these into the separate sources and sinks: \\begin{aligned} & \\text{neutrons leaking from } dV/s \\text{neutrons absorbed in } dV/s = \\\\ & \\text{neutrons emitted in } dV/s + \\text{fission neutrons produced in } dV/s \\end{aligned} Where: \\text{neutrons leaking from } dV/s = \\left( \\frac{\\partial}{\\partial x} J_x (x,y,z) + \\frac{\\partial}{\\partial y} J_y (x,y,z) + \\frac{\\partial}{\\partial z} J_z (x,y,z) \\right) dV \\text{neutrons absorbed in } dV/s = \\Sigma_a (x,y,z) \\phi(x,y,z) dV \\text{neutrons emitted in } dV/s = S (x,y,z) dV \\text{fission neutrons produced in } dV/s = \\nu \\Sigma_F (x,y,z) \\phi(x,y,z) dV Combining these and eliminating dV gives: \\frac{\\partial}{\\partial x} J*x (r) + \\frac{\\partial}{\\partial y} J_y (r) + \\frac{\\partial}{\\partial z} J_x (z) + \\Sigma*{a} (r) \\phi(r) = S(r) + \\nu \\Sigma_f (r) \\phi (r) Given the vector definitions: J(r) = \\hat{i} J_x (r) + \\hat{j} J_y (r) + \\hat{k} J_z (r) \\text{ and } \\nabla = \\hat{i} \\frac{\\partial}{\\partial x} + \\hat{j} \\frac{\\partial}{\\partial y} + \\hat{k} \\frac{\\partial}{\\partial z} We can write the balance equation as: \\nabla \\cdot J(r) + \\Sigma\\_{a} (r) \\phi(r) = S(r) + \\nu \\Sigma_f (r) \\phi (r) Given that we are using diffusion to describe the behaviour of neutrons within a reactor, we can therefore make use of Fick's Law, which states that any solute (the neutrons) will diffuse from an area of high concentration (high neutron flux) to an area of low concentration. This law gives an equation that will relate the current in a system to the concentration gradient multiplied by a diffusion coefficient. In the simplest 1-D reactor case the current of neutrons will therefore be given by the negative of a diffusion coefficient multiplied by the gradient of the flux. A general form of this can be seen below, where J is the neutron current (or diffusion flux), D is the diffusion coefficient and \\phi is the neutron flux. J = - D(r)\\nabla\\phi(r) This can be substituted into the full form of the balance equation to form the neutron diffusion equation: - \\nabla \\cdot D(r)\\nabla\\phi(r) + \\Sigma_{a} (r) \\phi(r) = S(r) + \\nu \\Sigma_f (r) \\phi (r) It is therefore also important to have an accurate method of calculation for the diffusion coefficient. The diffusion coefficient is equal to 1/3 multiplied by the inverse of the transport cross section. For simple neutron diffusion cases involving isotropic scatter, the transport cross section can be set to be equal to the total cross section, which is equal to the sum of the absorption and scattering (including self-scatter) cross sections. This can be seen below where \\Sigma_{tr} is the transport cross section, \\Sigma_{t} is the total cross section, \\Sigma_{a} is the absorption cross section and \\Sigma_{s} is the scattering cross section. D = \\frac{1}{3\\Sigma*{tr}} \\simeq \\frac{1}{3\\Sigma*{t}} = \\frac{1}{3(\\Sigma*{a}+\\Sigma*{s})} This relation exists as the transport cross section is defined as \\Sigma_{tr} = \\Sigma_{t} - \\bar{\\mu}\\Sigma_{s} , where \\bar{\\mu} is the average cosine of the scattering angle. This has a value of 0 in the laboratory system for isotropic scatter, so the transport and total cross sections can be approximated to one another in this case. This equation effectively relates the rate of change of neutrons within a system to a number of material properties and the flux, and hence can be solved with knowledge of the materials involved and the use of mathematical solvers. An example of the neutron diffusion equation can be seen below, for a 1-D slab reactor at steady state, where \\lambda is the eigenvalue of the system, \\nu is the average neutrons produced per fission and \\Sigma_f is the fission cross section. In this example a fission source of neutrons is being used instead of a simple volumetric source. -\\frac{d}{d x} D(x) \\frac{d \\phi(x)}{d x}+\\Sigma*{a}(x) \\phi(x)=\\frac{1}{\\lambda} \\nu \\Sigma*{f}(x) \\phi(x) Neutron diffusion codes will principally solve this equation to calculate the neutron flux over a specified geometry. Problems involving a fission neutron source can be solved for the eigenvalue \\lambda of the system, utilising a fission source normalisation.","title":"Appendix A - Theory"},{"location":"appendix/#appendix-a-theory","text":"","title":"Appendix A - Theory"},{"location":"appendix/#neutron-diffusion-theory","text":"In the design of any nuclear reactor, it is critical to understand the distribution of neutrons throughout the system. As neutrons move through various parts of the reactor such as the fuel or the moderator, their behaviour will greatly change based on the medium in which they find themselves. This neutron behaviour can be most simply approximated as a form of diffusion occurring within the reactor, producing a solvable equation which can be used to accurately describe this behaviour. The analysis and solving of this equation is known as neutron diffusion theory, and is a critical area of nuclear physics and engineering, used widely in the industry to calculate neutron flux profiles and multiplication factors within a reactor. The first step in generating this equation is to describe the spatial neutron balance within a volume dV , where dV = dx dy dz , centred at r , where r = (x,y,z) . Assuming steady state: \\text{neutrons lost in } dV/s = \\text{neutrons produced in } dV/s Splitting these into the separate sources and sinks: \\begin{aligned} & \\text{neutrons leaking from } dV/s \\text{neutrons absorbed in } dV/s = \\\\ & \\text{neutrons emitted in } dV/s + \\text{fission neutrons produced in } dV/s \\end{aligned} Where: \\text{neutrons leaking from } dV/s = \\left( \\frac{\\partial}{\\partial x} J_x (x,y,z) + \\frac{\\partial}{\\partial y} J_y (x,y,z) + \\frac{\\partial}{\\partial z} J_z (x,y,z) \\right) dV \\text{neutrons absorbed in } dV/s = \\Sigma_a (x,y,z) \\phi(x,y,z) dV \\text{neutrons emitted in } dV/s = S (x,y,z) dV \\text{fission neutrons produced in } dV/s = \\nu \\Sigma_F (x,y,z) \\phi(x,y,z) dV Combining these and eliminating dV gives: \\frac{\\partial}{\\partial x} J*x (r) + \\frac{\\partial}{\\partial y} J_y (r) + \\frac{\\partial}{\\partial z} J_x (z) + \\Sigma*{a} (r) \\phi(r) = S(r) + \\nu \\Sigma_f (r) \\phi (r) Given the vector definitions: J(r) = \\hat{i} J_x (r) + \\hat{j} J_y (r) + \\hat{k} J_z (r) \\text{ and } \\nabla = \\hat{i} \\frac{\\partial}{\\partial x} + \\hat{j} \\frac{\\partial}{\\partial y} + \\hat{k} \\frac{\\partial}{\\partial z} We can write the balance equation as: \\nabla \\cdot J(r) + \\Sigma\\_{a} (r) \\phi(r) = S(r) + \\nu \\Sigma_f (r) \\phi (r) Given that we are using diffusion to describe the behaviour of neutrons within a reactor, we can therefore make use of Fick's Law, which states that any solute (the neutrons) will diffuse from an area of high concentration (high neutron flux) to an area of low concentration. This law gives an equation that will relate the current in a system to the concentration gradient multiplied by a diffusion coefficient. In the simplest 1-D reactor case the current of neutrons will therefore be given by the negative of a diffusion coefficient multiplied by the gradient of the flux. A general form of this can be seen below, where J is the neutron current (or diffusion flux), D is the diffusion coefficient and \\phi is the neutron flux. J = - D(r)\\nabla\\phi(r) This can be substituted into the full form of the balance equation to form the neutron diffusion equation: - \\nabla \\cdot D(r)\\nabla\\phi(r) + \\Sigma_{a} (r) \\phi(r) = S(r) + \\nu \\Sigma_f (r) \\phi (r) It is therefore also important to have an accurate method of calculation for the diffusion coefficient. The diffusion coefficient is equal to 1/3 multiplied by the inverse of the transport cross section. For simple neutron diffusion cases involving isotropic scatter, the transport cross section can be set to be equal to the total cross section, which is equal to the sum of the absorption and scattering (including self-scatter) cross sections. This can be seen below where \\Sigma_{tr} is the transport cross section, \\Sigma_{t} is the total cross section, \\Sigma_{a} is the absorption cross section and \\Sigma_{s} is the scattering cross section. D = \\frac{1}{3\\Sigma*{tr}} \\simeq \\frac{1}{3\\Sigma*{t}} = \\frac{1}{3(\\Sigma*{a}+\\Sigma*{s})} This relation exists as the transport cross section is defined as \\Sigma_{tr} = \\Sigma_{t} - \\bar{\\mu}\\Sigma_{s} , where \\bar{\\mu} is the average cosine of the scattering angle. This has a value of 0 in the laboratory system for isotropic scatter, so the transport and total cross sections can be approximated to one another in this case. This equation effectively relates the rate of change of neutrons within a system to a number of material properties and the flux, and hence can be solved with knowledge of the materials involved and the use of mathematical solvers. An example of the neutron diffusion equation can be seen below, for a 1-D slab reactor at steady state, where \\lambda is the eigenvalue of the system, \\nu is the average neutrons produced per fission and \\Sigma_f is the fission cross section. In this example a fission source of neutrons is being used instead of a simple volumetric source. -\\frac{d}{d x} D(x) \\frac{d \\phi(x)}{d x}+\\Sigma*{a}(x) \\phi(x)=\\frac{1}{\\lambda} \\nu \\Sigma*{f}(x) \\phi(x) Neutron diffusion codes will principally solve this equation to calculate the neutron flux over a specified geometry. Problems involving a fission neutron source can be solved for the eigenvalue \\lambda of the system, utilising a fission source normalisation.","title":"Neutron Diffusion Theory"},{"location":"exercise/","text":"Exercises This section contains a number of suggested exercises that will give the user a deeper understanding of the topics covered in the above descriptions and utilised throughout this code. The exercises will increase progressively in complexity, with jumps in challenge roughly separated by the numeric ID of the exercise. Solutions to the exercises can be found in the solutions directory, where a version of the main code exists, modified such that it solves the problem. Where possible, changes made to the main code have been appropriately commented with a double dollar symbol such that users can more readily find these modifications. For example, changes made for exercise 1a can be found by searching for $$ Exercise 1a within the appropriate solution directory. Exercise 1a Task Add a print statement to the SetName Subroutine in the Materials Module Aims Gain an initial understanding of how a code can utilise an OOP structure For this exercise, add a print (or write) statement to the SetName Subroutine contained within the Materials Module, which prints the name of the material being set to the terminal. Exercise 1b Task Write a new subroutine which prints all material data stored in the module Aims Develop an understanding of Object Orientation Learn how to write a new subroutine and implement it in a class structure Learn how to utilise a type to call the generated routine Opportunity to gain experience with Fortran output formatting For this exercise, you must make your own subroutine within the Materials Module called PrintMaterial . This subroutine, when called from the Main, should print all material data contained within the materials class to the terminal. This is also a good opportunity for users to gain some experience with Fortran formatting if they wish, as this can make the terminal output much easier to read. Exercise 1c Task Make a new material which can be used in the input deck Aims Experience with Fortran logical arguments, namely IF statements Initial practice adjusting some existing logic within a subroutine For this exercise, a new material will be added to the list of those that the code can handle. The material Iron will be added with an absorption cross section of 4.0 and source of 0.1 . Exercise 2a Task Get input deck to instead explicitly read in material data rather than associating with a name Aims Experience making larger adjustments to the logic of the code Understanding of how to adjust various sections of a code to handle a modification Experience handling input files Currently, the code reads in a material name and then assigns material properties to the region based on a set of data stored in an If statement. For this exercise, the code will instead read in the absorption and source terms directly, such that Fuel would instead become 1.0 6.0 . To achieve this, the user will need to adjust the Problem module, as well as adjust how they have defined their problem in the input.in file. Exercise 2b Task Add another two sets of cell data to the .VTU file where the absorption and source material properties of each cell can be viewed Aims Gain experience writing data to an output file Learn how to utilise VTU files to add data sets to ParaView The current VTU file output contains the Flux, Cell Number and Region Number data sets. In this exercise, the user will add the Source term data set to the VTU output, such that the source value of each cell can be viewed in ParaView. An additional Cell Data set will need to be added which uses the known Region Numbers to pull data from the Materials Module. Exercise 3a Task Smear the problem into another dimension to produce a 3D ParaView output Aims Gain further experience writing data to an output file Learn how to utilise VTU files to generate more complex outputs in ParaView The main version of the code already smears a 1-dimensional flux profile into a second dimension for the sake of a visualisation example. This could be furthered by also smearing the results in a third dimension. To do so, the user will need to make an additional set of nodes that have been translated in the z axis and ensure that these are then associated with the correct cells. Users should utilise the ParaView VTK format guide to do so, noting that they will now need to define the cells as a three-dimensional shape. The VTK file format is described here: https://VTK.org/wp-content/uploads/2015/04/file-formats.pdf Exercise 3b Task Create a Compressed Diagonal Storage Module and switch it out for the existing CRS Module Aims Gain an understanding of how to write a completely new module and incorporate it into the OOP structure Gain experience with memory efficient programming Gain experience with abstract classes Currently, the non-PETSc version of the code utilises a CRS system for handling the matrices involved in the problem. For this task, the user should create their own module which performs the same task utilising Compressed Diagonal Storage (CDS). The CDS module should have all the features of the CRS, allowing it to be used with the polymorphic matrix constructor and solver that already exists within the code. The user should ensure that they have added their CDS module to the makefile, and allocated it as t_cds where this has been done for t_crs . As a stretch goal, the user could also compare the solve times with their CDS module against that of the original CRS. An explanation of the CDS methodology can be found at: http://netlib.org/linalg/html_templates/node94.html Possible Extension Exercise Task Make a wrapper for the BLAS/LAPACK library and use instead of PETSc/CG Aims Gain experience installing external libraries Understand how one can incorporate an external library into the code This extension exercise involves incorporating an additional external library into the code. BLAS and LAPACK are often used in professional codes as they utilise a number of highly optimised mathematical routines. To solve the problem, the user should utilise DGETRF and DGETRI to perform LU decomposition and inversion of the matrix, then multiply it by the source vector using DGEMV . The code can be installed easily on a Linux OS with the commands: sudo apt-get install libblas-dev liblapack-dev An explanation of how to use the code and each routine can be found at: http://www.netlib.org/lapack/explore-html/","title":"Exercises"},{"location":"exercise/#exercises","text":"This section contains a number of suggested exercises that will give the user a deeper understanding of the topics covered in the above descriptions and utilised throughout this code. The exercises will increase progressively in complexity, with jumps in challenge roughly separated by the numeric ID of the exercise. Solutions to the exercises can be found in the solutions directory, where a version of the main code exists, modified such that it solves the problem. Where possible, changes made to the main code have been appropriately commented with a double dollar symbol such that users can more readily find these modifications. For example, changes made for exercise 1a can be found by searching for $$ Exercise 1a within the appropriate solution directory.","title":"Exercises"},{"location":"exercise/#exercise-1a","text":"","title":"Exercise 1a"},{"location":"exercise/#task","text":"Add a print statement to the SetName Subroutine in the Materials Module","title":"Task"},{"location":"exercise/#aims","text":"Gain an initial understanding of how a code can utilise an OOP structure For this exercise, add a print (or write) statement to the SetName Subroutine contained within the Materials Module, which prints the name of the material being set to the terminal.","title":"Aims"},{"location":"exercise/#exercise-1b","text":"","title":"Exercise 1b"},{"location":"exercise/#task_1","text":"Write a new subroutine which prints all material data stored in the module","title":"Task"},{"location":"exercise/#aims_1","text":"Develop an understanding of Object Orientation Learn how to write a new subroutine and implement it in a class structure Learn how to utilise a type to call the generated routine Opportunity to gain experience with Fortran output formatting For this exercise, you must make your own subroutine within the Materials Module called PrintMaterial . This subroutine, when called from the Main, should print all material data contained within the materials class to the terminal. This is also a good opportunity for users to gain some experience with Fortran formatting if they wish, as this can make the terminal output much easier to read.","title":"Aims"},{"location":"exercise/#exercise-1c","text":"","title":"Exercise 1c"},{"location":"exercise/#task_2","text":"Make a new material which can be used in the input deck","title":"Task"},{"location":"exercise/#aims_2","text":"Experience with Fortran logical arguments, namely IF statements Initial practice adjusting some existing logic within a subroutine For this exercise, a new material will be added to the list of those that the code can handle. The material Iron will be added with an absorption cross section of 4.0 and source of 0.1 .","title":"Aims"},{"location":"exercise/#exercise-2a","text":"","title":"Exercise 2a"},{"location":"exercise/#task_3","text":"Get input deck to instead explicitly read in material data rather than associating with a name","title":"Task"},{"location":"exercise/#aims_3","text":"Experience making larger adjustments to the logic of the code Understanding of how to adjust various sections of a code to handle a modification Experience handling input files Currently, the code reads in a material name and then assigns material properties to the region based on a set of data stored in an If statement. For this exercise, the code will instead read in the absorption and source terms directly, such that Fuel would instead become 1.0 6.0 . To achieve this, the user will need to adjust the Problem module, as well as adjust how they have defined their problem in the input.in file.","title":"Aims"},{"location":"exercise/#exercise-2b","text":"","title":"Exercise 2b"},{"location":"exercise/#task_4","text":"Add another two sets of cell data to the .VTU file where the absorption and source material properties of each cell can be viewed","title":"Task"},{"location":"exercise/#aims_4","text":"Gain experience writing data to an output file Learn how to utilise VTU files to add data sets to ParaView The current VTU file output contains the Flux, Cell Number and Region Number data sets. In this exercise, the user will add the Source term data set to the VTU output, such that the source value of each cell can be viewed in ParaView. An additional Cell Data set will need to be added which uses the known Region Numbers to pull data from the Materials Module.","title":"Aims"},{"location":"exercise/#exercise-3a","text":"","title":"Exercise 3a"},{"location":"exercise/#task_5","text":"Smear the problem into another dimension to produce a 3D ParaView output","title":"Task"},{"location":"exercise/#aims_5","text":"Gain further experience writing data to an output file Learn how to utilise VTU files to generate more complex outputs in ParaView The main version of the code already smears a 1-dimensional flux profile into a second dimension for the sake of a visualisation example. This could be furthered by also smearing the results in a third dimension. To do so, the user will need to make an additional set of nodes that have been translated in the z axis and ensure that these are then associated with the correct cells. Users should utilise the ParaView VTK format guide to do so, noting that they will now need to define the cells as a three-dimensional shape. The VTK file format is described here: https://VTK.org/wp-content/uploads/2015/04/file-formats.pdf","title":"Aims"},{"location":"exercise/#exercise-3b","text":"","title":"Exercise 3b"},{"location":"exercise/#task_6","text":"Create a Compressed Diagonal Storage Module and switch it out for the existing CRS Module","title":"Task"},{"location":"exercise/#aims_6","text":"Gain an understanding of how to write a completely new module and incorporate it into the OOP structure Gain experience with memory efficient programming Gain experience with abstract classes Currently, the non-PETSc version of the code utilises a CRS system for handling the matrices involved in the problem. For this task, the user should create their own module which performs the same task utilising Compressed Diagonal Storage (CDS). The CDS module should have all the features of the CRS, allowing it to be used with the polymorphic matrix constructor and solver that already exists within the code. The user should ensure that they have added their CDS module to the makefile, and allocated it as t_cds where this has been done for t_crs . As a stretch goal, the user could also compare the solve times with their CDS module against that of the original CRS. An explanation of the CDS methodology can be found at: http://netlib.org/linalg/html_templates/node94.html","title":"Aims"},{"location":"exercise/#possible-extension-exercise","text":"","title":"Possible Extension Exercise"},{"location":"exercise/#task_7","text":"Make a wrapper for the BLAS/LAPACK library and use instead of PETSc/CG","title":"Task"},{"location":"exercise/#aims_7","text":"Gain experience installing external libraries Understand how one can incorporate an external library into the code This extension exercise involves incorporating an additional external library into the code. BLAS and LAPACK are often used in professional codes as they utilise a number of highly optimised mathematical routines. To solve the problem, the user should utilise DGETRF and DGETRI to perform LU decomposition and inversion of the matrix, then multiply it by the source vector using DGEMV . The code can be installed easily on a Linux OS with the commands: sudo apt-get install libblas-dev liblapack-dev An explanation of how to use the code and each routine can be found at: http://www.netlib.org/lapack/explore-html/","title":"Aims"}]}